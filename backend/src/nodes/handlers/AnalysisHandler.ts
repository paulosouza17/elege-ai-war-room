import { NodeHandler, ExecutionContext, NodeOutput } from '../NodeHandler';
import { interpolate } from '../utils/interpolate';
import { supabase } from '../../config/supabase';
import { AIService } from '../../services/aiService';

const AI_TIMEOUT_MS = 30_000; // 30 seconds max per AI call to prevent 10m executor timeouts

function withTimeout<T>(promise: Promise<T>, ms: number, label: string): Promise<T> {
    return new Promise<T>((resolve, reject) => {
        const timer = setTimeout(() => reject(new Error(`Timeout: ${label} exceeded ${ms / 1000}s`)), ms);
        promise.then(
            (val) => { clearTimeout(timer); resolve(val); },
            (err) => { clearTimeout(timer); reject(err); }
        );
    });
}

const RETRY_ATTEMPTS = 2;
const RETRY_DELAY_MS = 3_000; // 3 seconds between retries (reduced from 10s to prevent cascading timeouts)

async function withRetry<T>(fn: () => Promise<T>, label: string, logger: (msg: string) => Promise<void>): Promise<T> {
    let lastError: Error | null = null;
    for (let attempt = 1; attempt <= RETRY_ATTEMPTS; attempt++) {
        try {
            return await fn();
        } catch (err: any) {
            lastError = err;
            const isRetryable = /503|429|timeout|ECONNRESET|ETIMEDOUT|high demand/i.test(err.message || '');
            if (!isRetryable || attempt === RETRY_ATTEMPTS) {
                await logger(`[AnalysisHandler] ‚ùå Attempt ${attempt}/${RETRY_ATTEMPTS} failed (${label}): ${err.message}`);
                throw err;
            }
            await logger(`[AnalysisHandler] ‚ö† Attempt ${attempt}/${RETRY_ATTEMPTS} failed (${label}): ${err.message}. Retrying in ${RETRY_DELAY_MS / 1000}s...`);
            await new Promise(resolve => setTimeout(resolve, RETRY_DELAY_MS));
        }
    }
    throw lastError;
}

export class AnalysisHandler implements NodeHandler {
    async execute(node: any, context: ExecutionContext): Promise<NodeOutput> {
        await context.logger(`[AnalysisHandler] Analyzing content via AI...`);

        // 1. GATHER INPUT ‚Äî only items with actual content
        let itemsToAnalyze: any[] = [];

        for (const key in context.nodeOutputs) {
            const output = context.nodeOutputs[key];
            if (!output.data) continue;

            // Check for items array with actual article content
            if (Array.isArray(output.data.items)) {
                const contentItems = output.data.items.filter((item: any) =>
                    item.content || item.extractedText || item.summary
                );
                if (contentItems.length > 0) {
                    itemsToAnalyze.push(...contentItems);
                }
            }

            // Check for direct content fields (e.g. response_content from http nodes)
            if (output.data.response_content && !itemsToAnalyze.some((i: any) => i.content === output.data.response_content)) {
                itemsToAnalyze.push({
                    content: output.data.response_content,
                    title: output.data.response_title || 'Sem t√≠tulo',
                    url: output.data.response_url || '',
                    source: 'http_content',
                    media: output.data.response_media || [],
                });
            }

            // Check for manual uploads
            if (output.data.extractedText || output.data.fileUrl) {
                itemsToAnalyze.push({
                    content: output.data.extractedText || "Conte√∫do n√£o extra√≠vel (Imagem/PDF sem OCR)",
                    title: output.data.originalName,
                    source: 'manual_upload',
                    fileUrl: output.data.fileUrl,
                    isMultimodal: !!output.data.fileUrl,
                });
            }
        }

        // Fallback: use raw upstream data
        if (itemsToAnalyze.length === 0) {
            const allUpstreamData: Record<string, any> = {};
            for (const key in context.nodeOutputs) {
                const output = context.nodeOutputs[key];
                if (output?.data) {
                    const { _variables, _dynamic, ...cleanData } = output.data;
                    allUpstreamData[key] = cleanData;
                }
            }

            if (Object.keys(allUpstreamData).length > 0) {
                await context.logger(`[AnalysisHandler] No structured items found, using raw upstream data from ${Object.keys(allUpstreamData).length} nodes.`);
                itemsToAnalyze.push({
                    content: JSON.stringify(allUpstreamData, null, 2),
                    title: 'Dados de n√≥s anteriores',
                    source: 'upstream_nodes',
                });
            } else {
                return { success: false, error: "No content to analyze found from previous steps." };
            }
        }

        await context.logger(`[AnalysisHandler] Found ${itemsToAnalyze.length} items to analyze.`);

        // CAP: Limit items to prevent timeout (each AI call ‚âà 5-30s with retries)
        // 15 items √ó 30s worst-case = ~7.5 min ‚Äî fits within 5-10 min executor budget
        const MAX_ITEMS_PER_EXECUTION = 15;
        if (itemsToAnalyze.length > MAX_ITEMS_PER_EXECUTION) {
            await context.logger(`[AnalysisHandler] ‚ö† Capping from ${itemsToAnalyze.length} to ${MAX_ITEMS_PER_EXECUTION} items to prevent timeout.`);
            // Sort by engagement (highest first) to prioritize impactful content
            itemsToAnalyze.sort((a, b) => (b.engagement || b.likes || 0) - (a.engagement || a.likes || 0));
            itemsToAnalyze = itemsToAnalyze.slice(0, MAX_ITEMS_PER_EXECUTION);
        }

        // DEDUP: Skip items that already exist in intelligence_feed for this activation
        if (context.activationId && itemsToAnalyze.length > 0) {
            const urls = itemsToAnalyze.map(i => i.url).filter((u: string) => u && u.length >= 5);
            if (urls.length > 0) {
                const { data: existingRows } = await supabase
                    .from('intelligence_feed')
                    .select('url')
                    .in('url', urls)
                    .eq('activation_id', context.activationId);

                if (existingRows && existingRows.length > 0) {
                    const existingUrls = new Set(existingRows.map((r: any) => r.url));
                    const before = itemsToAnalyze.length;
                    itemsToAnalyze = itemsToAnalyze.filter(i => !i.url || !existingUrls.has(i.url));
                    const skipped = before - itemsToAnalyze.length;
                    if (skipped > 0) {
                        await context.logger(`[AnalysisHandler] ‚è≠ Dedup: skipped ${skipped} already-published item(s), ${itemsToAnalyze.length} remain for analysis.`);
                    }
                }
            }

            if (itemsToAnalyze.length === 0) {
                await context.logger(`[AnalysisHandler] ‚úÖ All items already exist in feed. Skipping AI analysis.`);
                return {
                    success: true,
                    data: {
                        items: [],
                        count: 0,
                        summary: 'Todos os itens j√° foram analisados anteriormente.',
                        _variables: { items: { label: 'Itens Analisados', type: 'list' }, count: { label: 'Quantidade', type: 'text' }, summary: { label: 'Resumo', type: 'text' } }
                    }
                };
            }
        }

        // Read node config
        const config = node.data || {};
        const userPrompt = config.prompt || '';
        const prePrompt = config.prePrompt || '';
        const outputFormat = config.outputFormat || 'json';
        const contextLinks = (config.contextLinks || '').split('\n').filter((l: string) => l.trim());

        const resolvedPrompt = interpolate(userPrompt, context);
        const modelOverride = config.model || '';

        const aiService = new AIService(supabase);
        const analyzedItems = [];

        // 2. FETCH MONITORED ENTITIES (Watchlist)
        let watchlistPrompt = "";
        let monitoredEntities: any[] = [];
        try {
            const { data: entities } = await supabase
                .from('monitored_entities')
                .select('*')
                .eq('user_id', context.userId);

            if (entities && entities.length > 0) {
                monitoredEntities = entities;
                watchlistPrompt = `
                ALVOS MONITORADOS (Entidades de Interesse):
                Abaixo est√° a lista de pessoas/organiza√ß√µes que estamos monitorando.
                Sua tarefa √© identificar se alguma dessas entidades √© mencionada no texto.

                CRIT√âRIOS DE IDENTIFICA√á√ÉO:
                1. Ocorr√™ncia exata ou aproximada do "Nome" principal.
                2. Ocorr√™ncia de QUALQUER um dos "Apelidos" listados.
                3. Identifica√ß√£o contextual clara baseada na "Descri√ß√£o".

                Lista de Alvos:
                ${entities.map(e => `- ID: ${e.id} | Nome: "${e.name}" | Apelidos: [${e.aliases?.join(', ')}] | Desc: "${e.description}"`).join('\n')}
                
                INSTRU√á√ÉO OBRIGAT√ìRIA:
                Se detectar qualquer um desses alvos (por nome ou apelido), voc√™ DEVE adicionar o ID correspondente ao array 'detected_entities' no JSON.
                Exemplo: "detected_entities": ["${entities[0].id}"]

                ‚ö† REGRA ANTI-VI√âS ‚Äî CR√çTICA:
                Voc√™ DEVE detectar entidades monitoradas INDEPENDENTE DO SENTIMENTO do artigo.
                Men√ß√µes POSITIVAS, NEUTRAS ou ELOGIOSAS tamb√©m devem ser detectadas.
                N√ÉO ignore uma entidade s√≥ porque ela est√° em contexto favor√°vel.
                Qualquer cita√ß√£o = detec√ß√£o obrigat√≥ria. Sentimento √© irrelevante para a detec√ß√£o.
                `;

                await context.logger(`[AnalysisHandler] Loaded ${entities.length} entities for watchlist.`);
            }
        } catch (err) {
            await context.logger(`[AnalysisHandler] Failed to load watchlist: ${err}`);
        }

        // 3a. GATHER ACTIVATION CONTEXT from trigger node output
        let activationPrompt = "";
        const triggerOutput = Object.values(context.nodeOutputs).find(
            (o: any) => o?.data?.trigger === 'activation'
        );
        if (triggerOutput) {
            const td = (triggerOutput as any).data;
            const parts: string[] = [];
            if (td.analysis_instructions) parts.push(`INSTRU√á√ïES DO OPERADOR (PRIORIDADE M√ÅXIMA):\n${td.analysis_instructions}`);
            if (td.keywords?.length) parts.push(`PALAVRAS-CHAVE MONITORADAS: ${td.keywords.join(', ')}`);
            if (td.people_of_interest?.length) parts.push(`PESSOAS DE INTERESSE: ${td.people_of_interest.join(', ')}`);
            if (td.briefing) parts.push(`BRIEFING: ${td.briefing}`);
            if (td.category) parts.push(`CATEGORIA: ${td.category}`);
            if (td.activation_name) parts.push(`ATIVA√á√ÉO: ${td.activation_name}`);
            if (parts.length > 0) {
                activationPrompt = `\nCONTEXTO DA ATIVA√á√ÉO:\n${parts.join('\n')}\n`;
                await context.logger(`[AnalysisHandler] Injecting activation context: ${td.keywords?.length || 0} keywords, ${td.people_of_interest?.length || 0} people${td.analysis_instructions ? ', with custom instructions' : ''}`);
            }
        }

        // 3b. GATHER UPSTREAM SCRIPT RESULTS (keyword/people matches already detected)
        let scriptContextPrompt = "";
        const scriptOutput = Object.values(context.nodeOutputs).find(
            (o: any) => o?.data?.keyword_matches || o?.data?.people_matches
        );
        if (scriptOutput) {
            const sd = (scriptOutput as any).data;
            const sparts: string[] = [];
            if (sd.keyword_matches?.length) sparts.push(`Keywords encontradas no texto: ${sd.keyword_matches.join(', ')}`);
            if (sd.people_matches?.length) sparts.push(`Pessoas encontradas no texto: ${sd.people_matches.join(', ')}`);
            if (sparts.length > 0) {
                scriptContextPrompt = `\nRESULTADOS PR√â-DETECTADOS:\n${sparts.join('\n')}\nUse estes dados como ponto de partida. Confirme e aprofunde a an√°lise.\n`;
            }
        }

        // 3c. DETECT PORTAL/SOURCE name from upstream
        let portalName = "";
        for (const key of Object.keys(context.nodeOutputs)) {
            const d = (context.nodeOutputs[key] as any)?.data;
            if (!d) continue;
            // Check loop aliases and items for portal-like objects
            for (const k of Object.keys(d)) {
                if (k.startsWith('_')) continue;
                const v = d[k];
                if (v && typeof v === 'object' && !Array.isArray(v) && v.name && v.type && v.url) {
                    portalName = v.name;
                    break;
                }
            }
            if (portalName) break;
        }

        // 4. ANALYZE EACH ITEM
        for (let i = 0; i < itemsToAnalyze.length; i++) {
            const item = itemsToAnalyze[i];
            await context.logger(`[AnalysisHandler] Processing item ${i + 1}/${itemsToAnalyze.length}: ${item.title || 'Sem t√≠tulo'}`);

            const perEntityInstruction = `
INSTRU√á√ÉO ‚Äî AN√ÅLISE POR ENTIDADE CITADA:
Se o texto mencionar pessoas ou organiza√ß√µes, retorne "per_entity_analysis" como array.
Formato para cada item:
{
  "entity_name": "Nome",
  "entity_id": "ID do alvo monitorado (se aplic√°vel, sen√£o null)",
  "sentiment": "positive|negative|neutral|mixed",
  "context": "Trecho resumido de como essa pessoa foi citada",
  "tone": "descritivo|cr√≠tico|elogioso|neutro|alarmista"
}
Se NENHUMA pessoa for citada, retorne "per_entity_analysis": [].
Inclua TODAS as pessoas citadas, independente do sentimento.

‚ö† REGRA DE SENTIMENTO ‚Äî PERSPECTIVA DO ALVO:
O "sentiment" de cada entidade deve refletir como o CONTE√öDO IMPACTA essa pessoa:
- "positive": apoio, elogio, endosso, defesa, promo√ß√£o da imagem. Ex: "X Presidente", "X √© o melhor", "Vote em X".
- "negative": cr√≠tica, ataque, den√∫ncia, associa√ß√£o com esc√¢ndalos, dano √† imagem.
- "neutral": men√ß√£o factual sem tom emocional claro.
- "mixed": o texto cont√©m elementos positivos E negativos para a mesma pessoa.

EXEMPLOS PARA CALIBRA√á√ÉO:
- "Fl√°vio Bolsonaro Presidente" ‚Üí sentiment: "positive" (endosso direto)
- "Soltem Bolsonaro" ‚Üí sentiment: "positive" (defesa, apoio)
- "X √© corrupto" ‚Üí sentiment: "negative" (ataque)
- "X disse que..." ‚Üí sentiment: "neutral" (factual)
- Ataques a advers√°rios que BENEFICIAM o alvo monitorado ‚Üí sentiment do alvo: "positive"
  Ex: "Lula ladr√£o, Fl√°vio Presidente" ‚Üí Fl√°vio=positive, Lula=negative

IMPORTANTE: Hashtags de apoio (#ImpeachmentDoX, #XPresidente) indicam o sentimento do autor.
Um tweet que DEFENDE ou PROMOVE algu√©m √© POSITIVO para essa pessoa, mesmo que critique outros.
`;

            // 3d. SOCIAL MEDIA SENTIMENT GUIDE ‚Äî injected when items come from Twitter/social_media
            let socialMediaSentimentGuide = '';
            const isSocialMedia = item.source === 'twitter' || item.source === 'x' ||
                item.source_type === 'social_media' || item.source_type === 'twitter' ||
                (item.url && /twitter\.com|x\.com/i.test(item.url)) ||
                item.author_username; // Twitter items always have author_username

            if (isSocialMedia) {
                socialMediaSentimentGuide = `
‚ö† ATEN√á√ÉO ‚Äî REGRAS PARA COMENT√ÅRIOS DE REDES SOCIAIS (TWITTER/X):
Coment√°rios de redes sociais s√£o CURTOS e usam linguagem informal.
N√ÉO classifique como "neutral" apenas porque o texto √© breve ou curto.
Avalie a INTEN√á√ÉO e o TOM do autor, n√£o apenas as palavras literais.

SINAIS DE SENTIMENTO POSITIVO (apoio/endosso) ‚Äî classifique como "positive":
- Bandeiras nacionais (üáßüá∑) = patriotismo/apoio ao alvo
- Emojis de for√ßa/aprova√ß√£o: üí™, üëè, ‚ù§Ô∏è, üôè, üî•, üëä
- "Nome + cargo futuro": "X Presidente", "X Governador", "X Senador" = endosso direto
- Apenas o nome + emojis positivos = demonstra√ß√£o de apoio
- "X crescendo", "X avan√ßando", "pesquisas apontam X crescendo" = narrativa favor√°vel
- Express√µes como "mito", "melhor", "gigante", "orgulho", "her√≥i", "futuro do Brasil"
- "Nem deveria pisar em solo X nessa campanha" (contexto de dom√≠nio) = elogio
- Hashtags de apoio: #XPresidente, #VoteX, #X2026
- Textos que s√≥ cont√™m emojis positivos (üáßüá∑üáßüá∑üáßüá∑, üí™üí™) = apoio

SINAIS DE SENTIMENTO NEGATIVO (ataque/cr√≠tica) ‚Äî classifique como "negative":
- "n√£o vale nada", "√© outro que n√£o vale nada" = deprecia√ß√£o
- "√© acusado de...", "acusado de..." = associa√ß√£o com esc√¢ndalo
- Termos de acusa√ß√£o: "rachadinha", "corrup√ß√£o", "indiciado", "investigado", "r√©u"
- "perde apoio", "derrotado", "fracassou", "perdeu" = narrativa de derrota
- Ironia/sarcasmo contra o alvo = negativo
- Xingamentos e g√≠rias ofensivas = negativo
- "N√£o merece", "vergonha", "mentiroso", "covarde", "traidor"
- "propaganda eleitoral antecipada" = associa√ß√£o com irregularidade

üé≠ DETEC√á√ÉO DE SARCASMO E IRONIA ‚Äî REGRAS OBRIGAT√ìRIAS:
Sarcasmo e ironia s√£o MUITO comuns em redes sociais e INVERTEM o sentido literal.
Se o texto usa ironia/sarcasmo CONTRA o alvo monitorado, classifique como "negative".
Se o texto usa ironia/sarcasmo A FAVOR do alvo (ironizando advers√°rios), classifique como "positive".
Padr√µes de sarcasmo/ironia a detectar:
- Elogio exagerado com inten√ß√£o oposta: "Parab√©ns, X! Destruiu o pa√≠s com sucesso!" ‚Üí NEGATIVO
- Uso de aspas de sarcasmo: "O 'honesto' senador..." ‚Üí NEGATIVO
- Perguntas ret√≥ricas: "Cad√™ o X agora?" ‚Üí geralmente NEGATIVO
- Falso apoio: "Confia no X que d√° certo ü§°" ‚Üí NEGATIVO (emoji de palha√ßo confirma sarcasmo)
- Ironia com advers√°rios para apoiar o alvo: "Dizem que X √© ruim, s√≥ ganhou todas as pesquisas" ‚Üí POSITIVO
- Tom de deboche: "kkkk", "aff", "t√° serto" combinados com men√ß√£o ao alvo ‚Üí avaliar contexto
REGRA: na d√∫vida entre ironia e sentido literal, considere o TOM GERAL do tweet e os emojis usados.

ü§¨ DETEC√á√ÉO DE XINGAMENTOS E LINGUAGEM OFENSIVA:
Qualquer xingamento ou g√≠ria ofensiva direcionada ao alvo = "negative" OBRIGAT√ìRIO.
Termos ofensivos comuns (brasileiros): "lixo", "vagabundo", "ladr√£o", "bandido", "fdp", "safado", "canalha", "pilantra", "verme", "imbecil", "idiota", "burro", "palha√ßo", "piada", "sem vergonha", "cara de pau"
Varia√ß√µes com abrevia√ß√µes: "vtnc", "pqp", "vsf", "tmj" (apoio)
G√≠rias de apoio (POSITIVO): "mito", "pai", "faz o L" (contexto pol√≠tico), "tamo junto", "tmj", "brabo"
REGRA: xingamento ao alvo = negative. Xingamento a advers√°rios do alvo = positive para o alvo.

üìä DICION√ÅRIO DE EMOJIS E SENTIMENTO:
Emojis POSITIVOS (apoio, amor, for√ßa):
üáßüá∑ = patriotismo/apoio | ‚ù§Ô∏èüíöüíõüíú = amor/apoio | üí™üëä‚úä = for√ßa/luta
üëèüôå = aplausos/aprova√ß√£o | üî• = intensidade positiva | üôè = gratid√£o/f√©
‚≠êüåü = destaque positivo | üèÜü•á = vit√≥ria | ‚úÖüëç = aprova√ß√£o
üòçü•∞ = admira√ß√£o | üéâüéä = celebra√ß√£o | ü´° = respeito

Emojis NEGATIVOS (cr√≠tica, rep√∫dio, deboche):
ü§° = deboche/chamando de palha√ßo | üí© = desprezo | ü§Æ = nojo/rep√∫dio
üëé = reprova√ß√£o | üò°ü§¨ = raiva | üö© = alerta/red flag
üíÄ‚ò†Ô∏è = "morri" (pode ser riso ou descren√ßa) | üóëÔ∏è = lixo/descarte
üò§ = frustra√ß√£o | üêç = trai√ß√£o | ü§• = chamando de mentiroso

Emojis AMB√çGUOS (dependem do contexto):
üòÇü§£ = riso (pode ser apoio ou deboche ‚Äî avaliar texto ao redor)
ü§î = d√∫vida/desconfian√ßa | üòè = sarcasmo ou confian√ßa
üëÄ = aten√ß√£o/exposi√ß√£o | üò¨ = constrangimento
REGRA: emojis SOZINHOS sem texto = avaliar pela combina√ß√£o. Ex: üáßüá∑üáßüá∑üáßüá∑ = positive, ü§°ü§°ü§° = negative.

REGRA ANTI-NEUTRALIDADE EXCESSIVA:
Em redes sociais, a MAIORIA dos coment√°rios expressa OPINI√ÉO, n√£o fato.
Se o coment√°rio cont√©m QUALQUER sinal emocional (emoji, tom, adjetivo, sarcasmo, xingamento), N√ÉO classifique como "neutral".
"neutral" deve ser RESERVADO para men√ß√µes PURAMENTE FACTUAIS sem tom opinativo.
Exemplo neutral v√°lido: "Fl√°vio Bolsonaro participou da reuni√£o no Senado"
Exemplo que N√ÉO √© neutral: "Fl√°vio Bolsonaro üáßüá∑üáßüá∑üáßüá∑" ‚Üí √© POSITIVE (apoio com emojis)
Exemplo que N√ÉO √© neutral: "X √© outro q n√£o vale nada" ‚Üí √© NEGATIVE (deprecia√ß√£o)
Exemplo que N√ÉO √© neutral: "Parab√©ns X ü§°" ‚Üí √© NEGATIVE (sarcasmo + emoji de deboche)
Exemplo que N√ÉO √© neutral: "X √© um lixo" ‚Üí √© NEGATIVE (xingamento)
`;
            }

            // Build activation-scoped framing
            let activationFraming = '';
            if (triggerOutput) {
                const td = (triggerOutput as any).data;
                const activationName = td.activation_name || '';
                activationFraming = `
ESCOPO DA AN√ÅLISE ‚Äî REGRAS CR√çTICAS:
Esta an√°lise faz parte do monitoramento "${activationName}".

1. ANALISE SOMENTE O QUE EST√Å NO TEXTO. N√£o invente, n√£o suponha, n√£o extrapole.
2. NUNCA mencione pessoas, entidades ou keywords que N√ÉO aparecem no texto.
   Se algu√©m n√£o √© citado no artigo, essa pessoa N√ÉO DEVE aparecer em nenhum campo da an√°lise.
3. Avalie o IMPACTO deste conte√∫do sob a perspectiva desta ativa√ß√£o.
4. Adicione ao JSON:
   - "activation_relevance": "high" | "medium" | "low" | "none"
   - "relevance_justification": breve justificativa da relev√¢ncia para "${activationName}"
5. Se o artigo n√£o tem rela√ß√£o direta com o contexto monitorado, classifique como "none" ou "low".

‚ö† CALIBRA√á√ÉO DO risk_score (0-100) ‚Äî ATEN√á√ÉO:
O risk_score mede o RISCO REPUTACIONAL PARA O ALVO MONITORADO, N√ÉO a relev√¢ncia.
Relev√¢ncia alta ‚â† risco alto. Um elogio √© altamente relevante mas tem risco BAIXO.

Escala obrigat√≥ria:
- 0-20: Conte√∫do POSITIVO ou NEUTRO para o alvo (elogio, apoio, endosso, defesa)
- 21-40: Men√ß√£o factual sem impacto reputacional significativo
- 41-60: Conte√∫do com potencial de risco moderado (pol√™mica, cr√≠tica branda)
- 61-80: Conte√∫do NEGATIVO real (ataque, esc√¢ndalo, den√∫ncia contra o alvo)
- 81-100: Crise reputacional grave (viral negativo, acusa√ß√£o criminal)

Exemplos:
- "X Presidente, vote em X" ‚Üí risk_score: 10 (apoio direto = risco zero)
- "X disse que vai investir em educa√ß√£o" ‚Üí risk_score: 25 (factual neutro)
- "Investiga√ß√£o apura atos de X" ‚Üí risk_score: 70 (risco real)
- "X indiciado por corrup√ß√£o" ‚Üí risk_score: 90 (crise)
`;

            }

            const prompt = `${prePrompt ? `${prePrompt}\n\n` : ''}${resolvedPrompt ? `${resolvedPrompt}\n\n` : ''}${!prePrompt && !resolvedPrompt ? 'Analise o conte√∫do a seguir com foco em intelig√™ncia pol√≠tica e narrativa.\n\n' : ''}${activationFraming}${activationPrompt}${scriptContextPrompt}${portalName ? `VE√çCULO/PORTAL DE ORIGEM: ${portalName}\n` : ''}${watchlistPrompt}${perEntityInstruction}${socialMediaSentimentGuide}
---
CONTE√öDO PARA AN√ÅLISE:
T√≠tulo: ${item.title || 'Sem t√≠tulo'}
${item.url ? `URL: ${item.url}` : ''}
Texto:
${(item.content || item.summary || '').substring(0, 8000)}
${contextLinks.length > 0 ? `\nLINKS DE CONTEXTO:\n${contextLinks.join('\n')}` : ''}`;


            try {
                let cleanJson = '';

                const isPlaceholder = item.content && item.content.includes("Conte√∫do n√£o extra√≠vel");

                if (item.fileUrl && (isPlaceholder || item.isMultimodal)) {
                    await context.logger(`[AnalysisHandler] Downloading file for multimodal analysis...`);
                    const axios = require('axios');
                    const response: any = await withTimeout(
                        axios.get(item.fileUrl, { responseType: 'arraybuffer', timeout: 30000 }),
                        30000,
                        'File download'
                    );
                    const fileBuffer = Buffer.from(response.data);

                    const ext = item.title?.split('.').pop()?.toLowerCase();
                    let mimeType = 'application/pdf';
                    if (['jpg', 'jpeg', 'png', 'webp'].includes(ext || '')) mimeType = `image/${ext === 'jpg' ? 'jpeg' : ext}`;

                    await context.logger(`[AnalysisHandler] Sending ${mimeType} (${fileBuffer.length} bytes) to Gemini...`);
                    const aiResponse = await withRetry(
                        () => withTimeout(
                            aiService.generateWithFile(prompt, fileBuffer, mimeType),
                            AI_TIMEOUT_MS,
                            'Gemini multimodal'
                        ),
                        'Gemini multimodal',
                        context.logger
                    );
                    cleanJson = aiResponse.replace(/```json/g, '').replace(/```/g, '').trim();

                } else {
                    await context.logger(`[AnalysisHandler] Sending text to AI (${prompt.length} chars)${modelOverride ? ` [model: ${modelOverride}]` : ''}...`);
                    const maxTokens = config.maxOutputTokens || 2048;
                    const aiResponse = await withRetry(
                        () => withTimeout(
                            aiService.generateRaw(prompt, modelOverride || undefined, maxTokens),
                            AI_TIMEOUT_MS,
                            'AI generateRaw'
                        ),
                        'AI generateRaw',
                        context.logger
                    );
                    cleanJson = aiResponse.replace(/```json/g, '').replace(/```/g, '').trim();
                }

                await context.logger(`[AnalysisHandler] AI Response received (${cleanJson.length} chars).`);

                if (outputFormat === 'text') {
                    analyzedItems.push({
                        ...item,
                        summary: cleanJson,
                        raw_text: cleanJson,
                        analyzed_at: new Date().toISOString()
                    });
                } else {
                    let analysisData;
                    try {
                        analysisData = JSON.parse(cleanJson);
                    } catch (parseError) {
                        await context.logger(`[AnalysisHandler] ‚ö† JSON Parse Failed. Using fallback risk_score=51. Raw: ${cleanJson.substring(0, 200)}`);
                        analysisData = {
                            summary: cleanJson.substring(0, 500),
                            risk_score: 51,
                            sentiment: 'neutral',
                            keywords: [],
                            entities: [],
                            detected_entities: []
                        };
                    }

                    // POST-PROCESS: Normalize detected_entities ‚Äî convert names to UUIDs
                    if (monitoredEntities.length > 0 && Array.isArray(analysisData.detected_entities)) {
                        const validIds = new Set(monitoredEntities.map(e => e.id));
                        const normalizedIds: string[] = [];

                        for (const val of analysisData.detected_entities) {
                            if (validIds.has(val)) {
                                // Already a valid UUID
                                normalizedIds.push(val);
                            } else if (typeof val === 'string') {
                                // AI returned a name ‚Äî match against name/aliases
                                const match = monitoredEntities.find(e =>
                                    e.name.toLowerCase() === val.toLowerCase() ||
                                    (e.aliases || []).some((a: string) => a.toLowerCase() === val.toLowerCase())
                                );
                                if (match) {
                                    normalizedIds.push(match.id);
                                    await context.logger(`[AnalysisHandler] Normalized entity name "${val}" ‚Üí UUID ${match.id}`);
                                }
                            }
                        }
                        analysisData.detected_entities = [...new Set(normalizedIds)];
                    }

                    // POST-PROCESS: Normalize per_entity_analysis entity_id the same way
                    if (monitoredEntities.length > 0 && Array.isArray(analysisData.per_entity_analysis)) {
                        const validIds = new Set(monitoredEntities.map(e => e.id));
                        for (const ea of analysisData.per_entity_analysis) {
                            if (ea.entity_id && !validIds.has(ea.entity_id)) {
                                // entity_id is invalid ‚Äî try to match by entity_name
                                const match = monitoredEntities.find(e =>
                                    e.name.toLowerCase() === (ea.entity_name || '').toLowerCase() ||
                                    (e.aliases || []).some((a: string) => a.toLowerCase() === (ea.entity_name || '').toLowerCase())
                                );
                                ea.entity_id = match ? match.id : null;
                            }
                            // Also ensure entity_id is set when entity_name matches a monitored entity
                            if (!ea.entity_id && ea.entity_name) {
                                const match = monitoredEntities.find(e =>
                                    e.name.toLowerCase() === ea.entity_name.toLowerCase() ||
                                    (e.aliases || []).some((a: string) => a.toLowerCase() === ea.entity_name.toLowerCase())
                                );
                                if (match) ea.entity_id = match.id;
                            }
                        }
                    }

                    // POST-PROCESS: Normalize all standard fields from AI response
                    // 1. Summary ‚Äî always clean readable text, never JSON
                    if (!analysisData.summary || typeof analysisData.summary !== 'string' || analysisData.summary.trim().startsWith('{')) {
                        analysisData.summary =
                            analysisData.relevance_justification ||
                            analysisData.context_analysis ||
                            analysisData.relevance_explanation ||
                            (item.content || item.title || '').substring(0, 500) ||
                            'An√°lise realizada sem resumo dispon√≠vel.';
                    }

                    // 2. Risk score ‚Äî derive from activation_relevance if AI didn't provide one
                    // Relevance != Risk: high relevance just means it's about the target, not that it's risky
                    if (!analysisData.risk_score || analysisData.risk_score === 0) {
                        const relevanceMap: Record<string, number> = { high: 50, medium: 35, low: 20, none: 5 };
                        const baseScore = relevanceMap[analysisData.activation_relevance] || 30;

                        // Only boost risk if the MONITORED TARGET has negative sentiment (not bystander entities)
                        const monitoredEntityIds = new Set(monitoredEntities.map(e => e.id));
                        const monitoredEntityNames = new Set(monitoredEntities.map(e => e.name.toLowerCase()));
                        const targetNegative = (analysisData.per_entity_analysis || []).some((ea: any) =>
                            ea.sentiment === 'negative' && (
                                monitoredEntityIds.has(ea.entity_id) ||
                                monitoredEntityNames.has((ea.entity_name || '').toLowerCase())
                            )
                        );
                        analysisData.risk_score = targetNegative ? Math.min(baseScore + 15, 95) : baseScore;
                    }

                    // 2b. Risk score post-processing ‚Äî override when AI confuses relevance with risk
                    // If monitored target sentiment is positive/neutral but AI gave high risk, cap it
                    if (analysisData.risk_score >= 60 && monitoredEntities.length > 0) {
                        const monitoredEntityIds = new Set(monitoredEntities.map(e => e.id));
                        const monitoredEntityNames = new Set(monitoredEntities.map(e => e.name.toLowerCase()));
                        const targetAnalyses = (analysisData.per_entity_analysis || []).filter((ea: any) =>
                            monitoredEntityIds.has(ea.entity_id) ||
                            monitoredEntityNames.has((ea.entity_name || '').toLowerCase())
                        );
                        const allTargetsPositiveOrNeutral = targetAnalyses.length > 0 &&
                            targetAnalyses.every((ea: any) => ea.sentiment === 'positive' || ea.sentiment === 'neutral');
                        if (allTargetsPositiveOrNeutral) {
                            analysisData.risk_score = Math.min(analysisData.risk_score, 35);
                        }
                    }

                    // 3. Sentiment ‚Äî derive from MONITORED TARGET's per_entity sentiment
                    // Use the sentiment of the monitored entity, not any random entity
                    if (!analysisData.sentiment || analysisData.sentiment === 'neutral') {
                        const monitoredEntityIds = new Set(monitoredEntities.map(e => e.id));
                        const monitoredEntityNames = new Set(monitoredEntities.map(e => e.name.toLowerCase()));

                        // Find the per-entity analysis for the monitored target(s)
                        const targetAnalyses = (analysisData.per_entity_analysis || []).filter((ea: any) =>
                            monitoredEntityIds.has(ea.entity_id) ||
                            monitoredEntityNames.has((ea.entity_name || '').toLowerCase())
                        );

                        if (targetAnalyses.length > 0) {
                            // Use the monitored target's sentiment
                            const targetSentiments = targetAnalyses.map((ea: any) => ea.sentiment);
                            if (targetSentiments.includes('negative')) analysisData.sentiment = 'negative';
                            else if (targetSentiments.includes('positive')) analysisData.sentiment = 'positive';
                            else if (targetSentiments.includes('mixed')) analysisData.sentiment = 'mixed';
                        } else {
                            // No monitored entity found ‚Äî fall back to any entity
                            const sentiments = (analysisData.per_entity_analysis || []).map((e: any) => e.sentiment);
                            if (sentiments.includes('negative')) analysisData.sentiment = 'negative';
                            else if (sentiments.includes('positive')) analysisData.sentiment = 'positive';
                            else if (sentiments.includes('mixed')) analysisData.sentiment = 'mixed';
                        }
                    }

                    // 4. Keywords ‚Äî extract from content if AI didn't provide any
                    if (!analysisData.keywords || analysisData.keywords.length === 0) {
                        const entityNames = (analysisData.per_entity_analysis || []).map((e: any) => e.entity_name).filter(Boolean);
                        if (entityNames.length > 0) {
                            analysisData.keywords = entityNames;
                        }
                    }

                    // Merge: item fields first, then AI analysis overwrites
                    // BUT preserve critical source fields from the original item
                    // (AI response may contain generic source/source_type that would overwrite
                    //  the real values like source:'twitter', source_type:'social_media')
                    const preservedFields: Record<string, any> = {};
                    const fieldsToPreserve = [
                        'source', 'source_type', 'source_name', 'url', 'published_at',
                        // Twitter/X author metadata (from TwitterHandler)
                        'author_name', 'author_username', 'author_profile_image',
                        'author_followers', 'author_verified',
                        'likes', 'retweets', 'replies', 'impressions', 'engagement',
                    ];
                    for (const field of fieldsToPreserve) {
                        if (item[field]) preservedFields[field] = item[field];
                    }

                    const mergedItem = {
                        ...item,
                        ...analysisData,
                        ...preservedFields, // Re-apply original source fields AFTER AI data
                        analyzed_at: new Date().toISOString()
                    };

                    analyzedItems.push(mergedItem);
                }
            } catch (e: any) {
                await context.logger(`[AnalysisHandler] ‚ùå Error on item ${i + 1} after ${RETRY_ATTEMPTS} attempts: ${e.message}. Using fallback risk_score=51.`);
                analyzedItems.push({
                    ...item,
                    error: e.message,
                    summary: `Erro na an√°lise (ap√≥s ${RETRY_ATTEMPTS} tentativas): ${e.message}`,
                    risk_score: 51,
                    sentiment: 'neutral',
                    keywords: [],
                    entities: [],
                    detected_entities: []
                });
            }
        }

        await context.logger(`[AnalysisHandler] ‚úÖ Completed. ${analyzedItems.length} items analyzed.`);

        // Build dynamic _variables from first analyzed item's keys
        const baseVars: Record<string, any> = {
            summary: { label: 'Resumo IA', type: 'text' },
            items: { label: 'Itens Analisados', type: 'list' },
            count: { label: 'Quantidade', type: 'text' },
        };

        // Expose all AI response fields as variables
        if (analyzedItems.length > 0) {
            const firstItem = analyzedItems[0];
            const labelMap: Record<string, string> = {
                title: 'T√≠tulo', risk_score: 'Score de Risco', sentiment: 'Sentimento',
                source_name: 'Ve√≠culo', content_type_detected: 'Tipo de Conte√∫do',
                keywords: 'Palavras-chave', entities: 'Entidades', people_found: 'Pessoas Encontradas',
                keyword_matches: 'Keywords Detectadas', relevance_explanation: 'Relev√¢ncia',
                context_analysis: 'An√°lise Contextual', detected_entities: 'Entidades Detectadas',
            };
            for (const key of Object.keys(firstItem)) {
                if (key.startsWith('_') || baseVars[key]) continue;
                const val = firstItem[key];
                baseVars[key] = {
                    label: labelMap[key] || key,
                    type: Array.isArray(val) ? 'list' : typeof val === 'number' ? 'number' : 'text',
                };
            }
        }

        // Flatten first item fields to top level for easy variable access
        const topLevelData: Record<string, any> = {
            items: analyzedItems,
            count: analyzedItems.length,
            summary: analyzedItems.length > 0 ? analyzedItems[0].summary || '' : '',
        };
        if (analyzedItems.length > 0) {
            const first = analyzedItems[0];
            for (const key of Object.keys(first)) {
                if (key.startsWith('_') || topLevelData[key] !== undefined) continue;
                topLevelData[key] = first[key];
            }
        }
        topLevelData._variables = baseVars;

        return {
            success: true,
            data: topLevelData,
        };
    }
}
